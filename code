{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Protein Secondary Structure Prediction\n",
        "Using a Hidden Markov Model to Classify Amino Acid Sequences into Secondary Structure states in order to understand protein folding\n",
        "#Names\n",
        "Anila Chundi, Ranjini Ramesh, Shalini Sivakumar\n",
        "\n"
      ],
      "metadata": {
        "id": "7X3sK0ES9zrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install libraries\n",
        "\n",
        "! pip install nose\n",
        "! pip install numpy\n",
        "! pip install pandas\n",
        "! pip install matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0RVrEro-wF_",
        "outputId": "38251441-bd0b-418e-ccc5-653f44152979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nose\n",
            "Successfully installed nose-1.3.7\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CB513 Dataset\n",
        "- The CB513 dataset is a benchmark dataset widely used for training and testing protein secondary structure prediction models. It contains 513 protein sequences with annotated secondary structures.\n",
        "- dataset is from here: https://huggingface.co/datasets/proteinea/secondary_structure_prediction/blob/main/CB513.csv\n",
        "\n",
        "#DSSP Dataset\n",
        "- The DSSP (Dictionary of Secondary Structure in Proteins) dataset provides detailed secondary structure assignments for protein entries in the Protein Data Bank (PDB).\n"
      ],
      "metadata": {
        "id": "hf-UetX1LgQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download data here\n",
        "\n",
        "! wget -c 'https://huggingface.co/datasets/proteinea/secondary_structure_prediction/resolve/main/CB513.csv' -O CB513.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeo4pk3CLevX",
        "outputId": "4e4f343c-ed3d-4465-ec92-49ad019b15dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-28 19:16:40--  https://huggingface.co/datasets/proteinea/secondary_structure_prediction/resolve/main/CB513.csv\n",
            "Resolving huggingface.co (huggingface.co)... 3.168.73.106, 3.168.73.129, 3.168.73.111, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.168.73.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1585692 (1.5M) [text/plain]\n",
            "Saving to: ‘CB513.csv’\n",
            "\n",
            "\rCB513.csv             0%[                    ]       0  --.-KB/s               \rCB513.csv           100%[===================>]   1.51M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-11-28 19:16:40 (11.1 MB/s) - ‘CB513.csv’ saved [1585692/1585692]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import sys\n",
        "\n",
        "import nose.tools as nt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Ts4PbWAT_FcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Parsing\n",
        "- read and understand data in datasets\n",
        "\n",
        "**CB513_data**\n",
        "- \"input\" column contains the amino acid sequences for each protein\n",
        "  - each row represents a protein sequence as a long string of one-letter amino acid codes\n",
        "- \"dssp3\" column represents the secondary structure annotation for the corresponding protein in \"3-class DSSP\" format\n",
        "  - H: Helix, E: Strand(beta sheet), C: Coil\n",
        "  - each char corresponds to the secondary structure of the amino acid in the input column at the same position\n",
        "- \"dssp8\" column represents the secondary structure annotation for the corresponding protein in \"8-class DSSP\" format\n",
        "  - H: Alpha Helix, E: Extended Strand, C: Coil, G: 3/10 helix, I: π-helix, B: Isolated β-bridge, T: Turn, S: Bend\n",
        "  - each char corresponds to the secondary structure of the amino acid in the input column at the same position\n",
        "- \"disorder\" column indicates a region without a stable secondary structure\n",
        "  - values: 1 = Disordered, 0 = Ordered\n",
        "- \"cb513_mask\" column serves as a mask used to exclude padding, invalid data, etc\n",
        "  - 1 = valid, 0 = invalid"
      ],
      "metadata": {
        "id": "5XGGgBtJNHZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file into a DataFrame\n",
        "cb513_data = pd.read_csv('CB513.csv')\n",
        "\n",
        "print(cb513_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UpU7obvNFxL",
        "outputId": "f189c46d-57b0-4df3-dcbf-96d61f860787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               input  \\\n",
            "0  RTDCYGNVNRIDTTGASCKTAKPEGLSYCGVSASKKIAERDLQAMD...   \n",
            "1  GKITFYEDRGFQGRHYECSSDHSNLQPYFSRCNSIRVDSGCWMLYE...   \n",
            "2  MFKVYGYDSNIHKCVYCDNAKRLLTVKKQPFEFINIMPEKGVFDDE...   \n",
            "3  APAFSVSPASGASDGQSVSVSVAAAGETYYIAQCAPVGGQDACNPA...   \n",
            "4  TPAFNKPKVELHVHLDGAIKPETILYFGKKRGIALPADTVEELRNI...   \n",
            "\n",
            "                                               dssp3  \\\n",
            "0  CCCCCCCHHHCCCCCECHHHHCCCCCCCCEHHHHHHHHHHCHHHHH...   \n",
            "1  CEEEEEEECCCEEEEEEECCCECCCCCCCCCCCEEEEEECEEEEEC...   \n",
            "2  CEEEEECCCCCCCCHHHHHHHHHHHHCCCCEEEEECCCECCECCHH...   \n",
            "3  CCEEEEECCCCCCCCCEEEEEEECCCCEEEEEEECEECCEECCCCC...   \n",
            "4  CCCCCCCEEEEEEEHHHCCCHHHHHHHHHHHCCCCCCCCHHHHHHH...   \n",
            "\n",
            "                                               dssp8  \\\n",
            "0  CCCTTCCGGGSCCCCBCHHHHTTTTCSCCBHHHHHHHHHHTHHHHH...   \n",
            "1  CEEEEEEETTTEEEEEEECSCBSCCTTTCSCCSEEEEEESEEEEES...   \n",
            "2  CEEEEECCTTTSCCHHHHHHHHHHHHTTCCEEEEESCSBTTBCCHH...   \n",
            "3  CCEEEEECCSSCCSSCEEEEEEESCCSEEEEEEECEETTEECCCTT...   \n",
            "4  CCSCCSCEEEEEEEGGGSCCHHHHHHHHHHHTCCCSCSSHHHHHHH...   \n",
            "\n",
            "                                            disorder  \\\n",
            "0  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....   \n",
            "1  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....   \n",
            "2  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....   \n",
            "3  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....   \n",
            "4  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....   \n",
            "\n",
            "                                          cb513_mask  \n",
            "0  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....  \n",
            "1  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....  \n",
            "2  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....  \n",
            "3  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....  \n",
            "4  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HMM Training\n",
        "- Use previous dataset to train the HMM model\n",
        "  - Use input column as the 'observed states'\n",
        "  - Use dssp3 as hidden states"
      ],
      "metadata": {
        "id": "hwffLobERAt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "observed_states = cb513_data['input'].tolist()\n",
        "hidden_states = cb513_data['dssp3'].tolist()\n",
        "\n",
        "# print(observed_states)\n",
        "# print(hidden_states)\n",
        "\n",
        "for obs, hid in zip(observed_states, hidden_states):\n",
        "  assert(len(obs) == len(hid))\n",
        "\n",
        "hmm_data = list(zip(observed_states, hidden_states))"
      ],
      "metadata": {
        "id": "BgnHtKFfUHv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compute Initial, Emission, Transition log Probabilities"
      ],
      "metadata": {
        "id": "_bYmKW7FVcPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def compute_initial_probs(data):\n",
        "    # Count occurrences of initial hidden states\n",
        "    initial_counts = Counter(hid_seq[0] for _, hid_seq in data)\n",
        "\n",
        "    # Compute initial probabilities with smoothing\n",
        "    total_initials = sum(initial_counts.values())\n",
        "    initial_probs = {hid: (count + 1) / (total_initials + 3) for hid, count in initial_counts.items()}\n",
        "    return initial_probs\n",
        "\n",
        "initial_probs = compute_initial_probs(hmm_data)\n",
        "\n",
        "def compute_emission_probs(data):\n",
        "    # Count occurrences of (hidden_state, observed_state) pairs\n",
        "    emission_counts = {}\n",
        "    hidden_counts = Counter()\n",
        "\n",
        "    for obs_seq, hid_seq in data:\n",
        "        for obs, hid in zip(obs_seq, hid_seq):\n",
        "            if hid not in emission_counts:\n",
        "                emission_counts[hid] = Counter()\n",
        "            emission_counts[hid][obs] += 1\n",
        "            hidden_counts[hid] += 1\n",
        "\n",
        "    # Compute emission probabilities with smoothing\n",
        "    emission_probs = {\n",
        "        hid: {obs: (count + 1) / (hidden_counts[hid] + 20) for obs, count in obs_count.items()}\n",
        "        for hid, obs_count in emission_counts.items()\n",
        "    }\n",
        "    return emission_probs\n",
        "\n",
        "emission_probs = compute_emission_probs(hmm_data)\n",
        "\n",
        "\n",
        "def compute_transition_probs(data):\n",
        "    # Count occurrences of (prev_hidden_state, current_hidden_state) pairs\n",
        "    transition_counts = Counter()\n",
        "    total_transitions = Counter()\n",
        "\n",
        "    for _, hid_seq in data:\n",
        "        for i in range(1, len(hid_seq)):\n",
        "            transition_counts[(hid_seq[i-1], hid_seq[i])] += 1\n",
        "            total_transitions[hid_seq[i-1]] += 1\n",
        "\n",
        "    # Compute transition probabilities with smoothing\n",
        "    transition_probs = {\n",
        "        (prev, curr): (count + 1) / (total_transitions[prev] + 3)\n",
        "        for (prev, curr), count in transition_counts.items()\n",
        "    }\n",
        "    return transition_probs\n",
        "\n",
        "transition_probs = compute_transition_probs(hmm_data)"
      ],
      "metadata": {
        "id": "m1b3XVJoVG13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implement Viterbi Algorithm"
      ],
      "metadata": {
        "id": "-k04PT03VY_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def viterbi(obs_seq, states, initial_probs, emission_probs, transition_probs):\n",
        "    n = len(obs_seq)\n",
        "    v = {state: [float('-inf')] * n for state in states}\n",
        "    backpointer = {state: [None] * n for state in states}\n",
        "\n",
        "    # Initialization\n",
        "    for state in states:\n",
        "        v[state][0] = np.log(initial_probs[state]) + np.log(emission_probs[state].get(obs_seq[0], 1e-6))\n",
        "\n",
        "    # Recursion\n",
        "    for t in range(1, n):\n",
        "        for curr_state in states:\n",
        "            max_prob, prev_state = max(\n",
        "                (v[prev_state][t-1] + np.log(transition_probs.get((prev_state, curr_state), 1e-6)), prev_state)\n",
        "                for prev_state in states\n",
        "            )\n",
        "            v[curr_state][t] = max_prob + np.log(emission_probs[curr_state].get(obs_seq[t], 1e-6))\n",
        "            backpointer[curr_state][t] = prev_state\n",
        "\n",
        "    # Termination\n",
        "    max_final_state = max(states, key=lambda state: v[state][-1])\n",
        "    max_final_prob = v[max_final_state][-1]\n",
        "\n",
        "    # Traceback\n",
        "    best_path = [max_final_state]\n",
        "    for t in range(n-1, 0, -1):\n",
        "        best_path.insert(0, backpointer[best_path[0]][t])\n",
        "\n",
        "    return best_path, max_final_prob"
      ],
      "metadata": {
        "id": "PGzuf3r3Vhbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Evaluation"
      ],
      "metadata": {
        "id": "DeolazBYVyCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "states = ['H', 'E', 'C']\n",
        "for obs_seq, true_hid_seq in hmm_data[:10]:\n",
        "    pred_hid_seq, prob = viterbi(obs_seq, states, initial_probs, emission_probs, transition_probs)\n",
        "    print(f\"True: {true_hid_seq}\")\n",
        "    print(f\"Pred: {''.join(pred_hid_seq)}\")\n",
        "    print(f\"Log Probability: {prob}\")"
      ],
      "metadata": {
        "id": "SAtxZPUEV3Ds",
        "outputId": "a9e58137-3381-4d24-adee-b75d03809690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'H'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0ab3a52cfc75>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'H'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'E'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'C'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobs_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_hid_seq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhmm_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpred_hid_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mviterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memission_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"True: {true_hid_seq}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Pred: {''.join(pred_hid_seq)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-ab46737d6004>\u001b[0m in \u001b[0;36mviterbi\u001b[0;34m(obs_seq, states, initial_probs, emission_probs, transition_probs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memission_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Recursion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'H'"
          ]
        }
      ]
    }
  ]
}
